{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "71t5ytFLYw69"
      },
      "source": [
        "## Ensemble using ML models with less accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH5WJxA7WbcH"
      },
      "outputs": [],
      "source": [
        "train_df=pd.read_csv(r'/content/drive/MyDrive/IR_project/train.csv')\n",
        "test_df=pd.read_csv(r'/content/drive/MyDrive/IR_project/test.csv')\n",
        "\n",
        "vectoriser = TfidfVectorizer(max_features = 100)\n",
        "xtr_df = vectoriser.fit_transform(train_df['preprocessed_data'])\n",
        "xt_df = vectoriser.fit_transform(test_df['preprocessed_data'])\n",
        "\n",
        "xtr=pd.DataFrame(xtr_df.toarray(),columns=vectoriser.get_feature_names_out())\n",
        "xt=pd.DataFrame(xt_df.toarray(),columns=vectoriser.get_feature_names_out())\n",
        "ytr=train_df['label']\n",
        "yt=test_df['label']\n",
        "\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(xtr)\n",
        "\n",
        "xtr = scaler.transform(xtr)\n",
        "xt = scaler.transform(xt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h54_xGmRVEkG",
        "outputId": "2e7737bc-a2c5-4d95-a92d-473d7379f96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.9387583892617449\n",
            "[[3289  106]\n",
            " [ 113   68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      3395\n",
            "           1       0.39      0.38      0.38       181\n",
            "\n",
            "    accuracy                           0.94      3576\n",
            "   macro avg       0.68      0.67      0.68      3576\n",
            "weighted avg       0.94      0.94      0.94      3576\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import load\n",
        "# Assuming that you have trained models saved in .h5 files\n",
        "model1 = load('/content/drive/MyDrive/IR_project/models/naive_bayes_model.joblib')\n",
        "model2 = load('/content/drive/MyDrive/IR_project/models/mlp_model.joblib')\n",
        "model3 = load('/content/drive/MyDrive/IR_project/models/svc_model.joblib')\n",
        "model4 = load('/content/drive/MyDrive/IR_project/models/knn_model.joblib')\n",
        "model5 = load('/content/drive/MyDrive/IR_project/models/random_forest_model.joblib')\n",
        "model6 = load('/content/drive/MyDrive/IR_project/models/decision_tree_model.joblib')\n",
        "\n",
        "\n",
        "ensemble_clf = VotingClassifier(estimators=[\n",
        "    ('naive_bayes', model1),('mlp_model', model2),\n",
        "    ('knn', model4)\n",
        "], voting='soft') # hard also giving the same accuracy\n",
        "\n",
        "ensemble_clf.fit(xtr, ytr)\n",
        "\n",
        "# Evaluate ensemble performance\n",
        "y_pred = ensemble_clf.predict(xt)\n",
        "print('Test Accuracy: ', accuracy_score(yt, y_pred))\n",
        "\n",
        "print(confusion_matrix(yt, y_pred))\n",
        "print(classification_report(yt, y_pred))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fM4Oz8t0aZxd"
      },
      "source": [
        "## Ensemble using Deep learning models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xqYsYS-Gafn1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKOMw919aivH"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_df=pd.read_csv(r'/content/drive/MyDrive/IR_project/train.csv')\n",
        "test_df=pd.read_csv(r'/content/drive/MyDrive/IR_project/test.csv')\n",
        "xtr=train_df['preprocessed_data']\n",
        "ytr=train_df['label']\n",
        "xt=test_df['preprocessed_data']\n",
        "yt=test_df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUsVKmkqddL-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import layers\n",
        "from gensim.models import KeyedVectors\n",
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.separate_heads(query, batch_size)\n",
        "        key = self.separate_heads(key, batch_size)\n",
        "        value = self.separate_heads(value, batch_size)\n",
        "\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3VYPmhedfYO"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cjk35YvdwO1"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "def build_model(max_len, vocab_size, embed_dim, num_heads, ff_dim):\n",
        "    inputs = layers.Input(shape=(max_len,))\n",
        "    embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "    x = transformer_block(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8YLMhgIcNc1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/IR_project/models/attention_tokenizer.pickle', 'rb') as handle:\n",
        "    loaded_tokenizer_attention = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/IR_project/models/word_level_tokenizer.pickle', 'rb') as handle:\n",
        "    loaded_tokenizer_cnn = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/IR_project/models/word_level_tokenizer_bilstm.pickle', 'rb') as handle:\n",
        "    loaded_tokenizer_bi_lstm_gru = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erfef7GKb7Kq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load your models and tokenizers\n",
        "cnn_model = load_model('/content/drive/MyDrive/IR_project/models/cnn_wordlevel.h5')\n",
        "bilstm_gru_model = load_model('/content/drive/MyDrive/IR_project/models/bi_gru_lstm_model_6.h5')\n",
        "transformer_model = load_model('/content/drive/MyDrive/IR_project/models/attention.h5',custom_objects={'TokenAndPositionEmbedding': TokenAndPositionEmbedding,\n",
        "                                          'TransformerBlock': TransformerBlock,\n",
        "                                          'MultiHeadSelfAttention': MultiHeadSelfAttention})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e14ZTyaF5H8w"
      },
      "outputs": [],
      "source": [
        "def ensemble_predict(texts, voting):\n",
        "\n",
        "  preds = []\n",
        "\n",
        "  # Preprocessing\n",
        "  cnn_text = loaded_tokenizer_cnn.texts_to_sequences(texts)\n",
        "  cnn_text = pad_sequences(cnn_text, maxlen=50)  # Adjust maxlen as needed\n",
        "\n",
        "  bilstm_gru_text = loaded_tokenizer_bi_lstm_gru.texts_to_sequences(texts)\n",
        "  bilstm_gru_text = pad_sequences(bilstm_gru_text, maxlen=50)  # Adjust maxlen as needed\n",
        "\n",
        "  transformer_text = loaded_tokenizer_attention.texts_to_sequences(texts)\n",
        "  transformer_text = pad_sequences(transformer_text, maxlen=512)  # Adjust maxlen as needed\n",
        "\n",
        "  # Predicting\n",
        "  cnn_pred = cnn_model.predict(cnn_text)\n",
        "  bilstm_gru_pred = bilstm_gru_model.predict(bilstm_gru_text)\n",
        "  transformer_pred = transformer_model.predict(transformer_text)\n",
        "\n",
        "  # Hard voting\n",
        "  if voting == 'hard':\n",
        "      for c, b, t in zip(cnn_pred, bilstm_gru_pred, transformer_pred):\n",
        "          votes = [np.argmax(c), np.argmax(b), np.argmax(t)]\n",
        "\n",
        "          counts = np.bincount(votes)\n",
        "\n",
        "          preds.append(np.argmax(counts))\n",
        "\n",
        "  # Soft voting\n",
        "  elif voting == 'soft':\n",
        "      average_pred = (cnn_pred + bilstm_gru_pred + transformer_pred) / 3\n",
        "      for x in average_pred:\n",
        "          preds.append(np.argmax(x))\n",
        "\n",
        "  return np.array(preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gso-TJH5JeF",
        "outputId": "21bc6b19-d25f-4dcd-de57-2c55299d6bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "112/112 [==============================] - 6s 2ms/step\n",
            "112/112 [==============================] - 3s 6ms/step\n",
            "112/112 [==============================] - 2s 16ms/step\n",
            "112/112 [==============================] - 0s 2ms/step\n",
            "112/112 [==============================] - 1s 5ms/step\n",
            "112/112 [==============================] - 2s 16ms/step\n",
            "Hard Voting Accuracy:  0.9493847874720358\n",
            "Soft Voting Accuracy:  0.9807046979865772\n",
            "Hard Voting Confusion Matrix: \n",
            " [[3395    0]\n",
            " [ 181    0]]\n",
            "Soft Voting Confusion Matrix: \n",
            " [[3369   26]\n",
            " [  43  138]]\n",
            "Hard Voting Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      3395\n",
            "           1       0.00      0.00      0.00       181\n",
            "\n",
            "    accuracy                           0.95      3576\n",
            "   macro avg       0.47      0.50      0.49      3576\n",
            "weighted avg       0.90      0.95      0.92      3576\n",
            "\n",
            "Soft Voting Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      3395\n",
            "           1       0.84      0.76      0.80       181\n",
            "\n",
            "    accuracy                           0.98      3576\n",
            "   macro avg       0.91      0.88      0.89      3576\n",
            "weighted avg       0.98      0.98      0.98      3576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Predict on the test set\n",
        "y_pred_hard = ensemble_predict(xt, voting='hard')\n",
        "y_pred_soft = ensemble_predict(xt, voting='soft')\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Hard Voting Accuracy: \", accuracy_score(yt, y_pred_hard))\n",
        "print(\"Soft Voting Accuracy: \", accuracy_score(yt, y_pred_soft))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Hard Voting Confusion Matrix: \\n\", confusion_matrix(yt, y_pred_hard))\n",
        "print(\"Soft Voting Confusion Matrix: \\n\", confusion_matrix(yt, y_pred_soft))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Hard Voting Classification Report: \\n\", classification_report(yt, y_pred_hard))\n",
        "print(\"Soft Voting Classification Report: \\n\", classification_report(yt, y_pred_soft))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
